{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Web Scraping:** \n",
    "**El web scraping es el proceso de extracción automatizada de datos de sitios web. Utiliza programas de software para recorrer páginas web, analizar su estructura y extraer información específica de ellas. Este proceso puede incluir la descarga de contenido web, el análisis de HTML para identificar patrones de datos y la extracción de datos relevantes según ciertos criterios, como etiquetas HTML específicas, clases CSS o ubicaciones en la página. El objetivo del web scraping es obtener datos de manera eficiente y automatizada para su posterior análisis, almacenamiento o uso en otras aplicaciones.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos librerias necesarias para nuestro trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Importar la librería pandas para manipulación y análisis de datos\n",
    "import os  # Importar el módulo os para operaciones relacionadas con el sistema operativo\n",
    "import re  # Importar el módulo re para operaciones de expresiones regulares\n",
    "import requests  # Importar el módulo requests para realizar solicitudes HTTP\n",
    "from bs4 import BeautifulSoup  # Importar BeautifulSoup desde el módulo bs4 para analizar HTML\n",
    "import fastparquet  # Importar la biblioteca fastparquet para leer y escribir archivos Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer WebScraping: página web de **Comisión de Taxis y Limusinas de Nueva York (TLC)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registros de viajes en taxis amarillos y verdes, incluye información sobre fechas, horas, ubicaciones, distancias, tarifas y tipos de pago. Estos datos fueron recopilados por proveedores tecnológicos autorizados y presentados a la Comisión de Taxis y Limusinas de Nueva York (TLC). https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-01.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-02.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-03.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-04.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-05.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-06.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-07.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-08.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-09.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-10.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-11.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2023-12.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\green_tripdata_2024-01.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-01.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-02.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-03.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-04.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-05.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-06.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-07.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-08.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-09.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-10.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-11.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2023-12.parquet\n",
      "Archivo descargado: ../0-DataSets/1-DatosScraping\\yellow_tripdata_2024-01.parquet\n"
     ]
    }
   ],
   "source": [
    "def create_directory(directory):\n",
    "    \"\"\"Crea un directorio si no existe.\"\"\"\n",
    "    if not os.path.exists(directory):  # Verificar si el directorio no existe\n",
    "        os.makedirs(directory)  # Crear el directorio si no existe\n",
    "\n",
    "def download_file(url, filename):\n",
    "    \"\"\"Descarga un archivo desde la URL y lo guarda con el nombre especificado.\"\"\"\n",
    "    response = requests.get(url)  # Realizar una solicitud GET a la URL especificada\n",
    "    if response.status_code == 200:  # Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "        with open(filename, 'wb') as file:  # Abrir el archivo en modo binario para escritura\n",
    "            file.write(response.content)  # Escribir el contenido de la respuesta en el archivo\n",
    "        print(f\"Archivo descargado: {filename}\")  # Imprimir un mensaje indicando que el archivo ha sido descargado\n",
    "\n",
    "# Crear carpeta de destino si no existe\n",
    "carpeta_destino = \"../0-DataSets/1-DatosScraping\"\n",
    "create_directory(carpeta_destino)\n",
    "\n",
    "# Obtener la lista de archivos en la carpeta de destino\n",
    "archivos_locales = os.listdir(carpeta_destino)\n",
    "\n",
    "# Generar enlaces para los meses del 01 al 12\n",
    "meses = []\n",
    "for nums in range(1,13):  # Iterar sobre números del 1 al 12\n",
    "    if nums < 10:\n",
    "        meses.append('0' + str(nums))  # Agregar un cero delante si el número es menor que 10\n",
    "    else:\n",
    "        meses.append(str(nums))  # Convertir el número a cadena y agregarlo sin modificar si es mayor o igual a 10\n",
    "\n",
    "# URL de la página web\n",
    "url = \"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "# Realizar la solicitud HTTP a la página\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verificar si la solicitud fue exitosa\n",
    "if response.status_code == 200:\n",
    "    # Parsear el contenido HTML de la página\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Encontrar todos los enlaces que contienen 'yellow' o 'green' y tienen el formato esperado para 2023\n",
    "    links_pagina = {a['href'] for a in soup.find_all('a', href=True) if re.match(r'^.*(yellow|green)_tripdata_(2023|2024)-\\d{2}\\.parquet$', a['href'])}\n",
    "\n",
    "    # Combinar enlaces generados dinámicamente con los obtenidos de la página\n",
    "    links_totales = links_pagina.copy()  # Crear una copia para mantener los enlaces originales\n",
    "\n",
    "    links_totales.update({\n",
    "        f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{año}-{mes}.parquet\" \n",
    "        for año in ['2023', '2024']  # Iterar sobre los años\n",
    "        for mes in meses\n",
    "    })\n",
    "    links_totales.update({\n",
    "        f\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_{año}-{mes}.parquet\" \n",
    "        for año in ['2023', '2024']  # Iterar sobre los años\n",
    "        for mes in meses\n",
    "    })\n",
    "\n",
    "    # Realizar la descarga de los archivos\n",
    "    for link in sorted(links_totales):  # Iterar sobre los enlaces ordenados alfabéticamente\n",
    "        nombre_archivo = link.split(\"/\")[-1]  # Obtener el nombre del archivo desde la URL\n",
    "        archivo_destino = os.path.join(carpeta_destino, nombre_archivo)  # Construir la ruta completa del archivo destino\n",
    "\n",
    "        if nombre_archivo not in archivos_locales:  # Verificar si el archivo no existe localmente\n",
    "            download_file(link, archivo_destino)  # Descargar el archivo desde el enlace proporcionado\n",
    "        else:\n",
    "            print(f\"El archivo {nombre_archivo} ya existe localmente.\")  # Imprimir un mensaje indicando que el archivo ya existe\n",
    "else:\n",
    "    print(f\"No se pudo acceder a la página. Código de estado: {response.status_code}\")  # Imprimir un mensaje de error si la solicitud no fue exitosa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizamos un `ETL` de los `archivos descargados` para tener un Dataset según proposito del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **`DICCIONARIO`** <br>* 'VendorID': Un código que indica el proveedor de LPEP que proporcionó el registro.<br>1= Tecnologías móviles creativas, LLC;<br> 2= ​​VeriFone Inc.<br>* 'lpep_pickup_datetime': La fecha y hora en que se activó el medidor.<br>* 'lpep_dropoff_datetime': La fecha y hora en que se desconectó el medidor.<br>* 'store_and_fwd_flag': Esta bandera indica si el registro de viaje se mantuvo en el vehículo.memoria antes de enviar al proveedor, también conocido como \"almacenar y reenviar\",porque el vehículo no tenía conexión con el servidor.<br>Y = viaje de almacenamiento y avance<br>N= no es un viaje de ida y vuelta<br>* 'RatecodeID': El código de tarifa final vigente al finalizar el viaje.<br>1= Tarifa estándar<br>2=JFK<br>3=Newark<br>4=Nasáu o Westchester<br>5=Tarifa negociada<br>6=viaje en grupo<br>* 'PULocationID': Zona de Taxi TLC en la que estaba activado el taxímetro<br>* 'DOLocationID': Zona de Taxi TLC en la que se desactivó el taxímetro<br>* 'passenger_count': El número de pasajeros en el vehículo. Este es un valor ingresado por el conductor.<br>* 'trip_distance': La distancia del viaje transcurrido en millas reportadas por el taxímetro.<br>* 'fare_amount': La tarifa de tiempo y distancia calculada por el taxímetro.<br>* 'extra': Extras y recargos varios. Actualmente esto sólo incluye los cargos de $0,50 y $1 por hora pico y por noche.<br>* 'mta_tax': Impuesto MTA de $0.50 que se activa automáticamente según el medidor tasa en uso.<br>* 'tip_amount': Monto de la propina: este campo se completa automáticamente para tarjetas de crédito. consejos. Las propinas en efectivo no están incluidas.<br>* 'tolls_amount': Importe total de todos los peajes pagados en el viaje.<br>* 'ehail_fee': ???<br>* 'improvement_surcharge': Recargo por mejora de $0.30 aplicado en viajes granizados en la bandera gota. El recargo por mejora comenzó a cobrarse en 2015.<br>* 'total_amount': El importe total cobrado a los pasajeros. No incluye propinas en efectivo.<br>* 'payment_type': Un código numérico que indica cómo el pasajero pagó el viaje.<br>1= tarjeta de crédito<br>2= ​​Efectivo<br>3= Sin cargo<br>4= Disputa<br>5= Desconocido<br>6= Viaje anulado<br>* 'trip_type': Un código que indica si el viaje fue un llamado callejero o un despacho.que se asigna automáticamente según la tarifa medida en uso, pero puede ser modificado por el conductor.<br>1= Granizo callejero<br>2= ​​Despacho<br>* 'congestion_surcharge':\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pfsh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
